# Segmentation-Depth Project
This repository hosts code used througout the development of the stereo vision segmentation and depth deep learning system.

The branch called main contains the model and other code for data preparation. The branch called master conatains the trained model weights. (I apologise for some lack of formatting, I am new to and still learning Github). The present model currently accepts a 256x256 stereo RGB image pair as input and outputs a segmented image for each image and a depth map computed from features extracted from the image pair. The model would probably require retraining to predict accurately on larger images although this is something we plan test the model on. WorkingModel.ipnyb is the development script I am using to develop the system. I am working on a deployment version that is easier to be used for general puropse and will upload as soon as it ready.

MaskCreation.py creates the semantic segmentation masks from the binary object masks created by Blender when rendering scenes. The masks are colour-coded consistently across scenes. The code, when run, prints out the colour codes used to code the objects masks but note that seeing as these masks are created using OpenCV these values are BGR as opposed to RGB so depending on how you pre-process your data you may need to reverse the contents of each tuple in order to get consistent results.

DataSort.py sorts raw data generated from Blender. It iterates through the 'images','seg_masks' & 'z_buffs' folders in each scene folder and saves the images in them into new folders called 'all_frames', 'all_masks' & 'all_zbuffs'. This simply streamlines the data upload to the universitys servers and the train/validation/test split but can realistically be done after upload while the data is still in it's original format.

In order to use the model in its current form, firstly you should prepare yor stereo images in two different folders in a format such as: 'left_image_folder/images/image_01.png', 'right_image_folder/images/image_01.png'. This is because the use of data generators requires a nested folder structure. The images can be saved at any size as they are automatically resized. Once you have done this, change the folder name in the StereoDepthGenTest function in cell 15 to match your folder names and change the batch size to however many image pair you would like to predict. Ensure that you have the model weights in the same folder as the script so they can be found for loading. The script will take a few seconds to run and should produce visualisations of the results at the end.

